#A propos

Apache Spark se présente comme la nouvelle génération de moteur de calcul distribué qui remplace progressivement Hadoop/MapReduce.

L'objet de ce Hands-on Labs est de vous familiariser par la pratique au traitement massif et distribué dans le domaine du data crunching et du machine learning. A l'issue de cette session, vous serez familiers avec :

- Les Resilient Data Sets (RDD) qui désignent l’abstraction essentielle pour la manipulation distribuée des données.

- les patterns de transformations et d'actions offerts par l'API

- les API de chargement et de stockage de données - filesystem / hdfs / NoSQL(Elasticsearch et Cassandra)

- Les bonnes pratiques de programmation distribuée avec la mise en oeuvre du partitionnement sélectif et l'usage de variables partagées (accumulators et broadcast variables)
- l'analyse et le reporting via Spark SQL
- l'analytique temps-réel avec Spark Streaming

Les prérequis à installer :

JDK 8
Distribution Spark et contenu du Hands-on Lab

ajout d'une modif de Gaspard
2e modif de gaspard
